# -*- coding: utf-8 -*-
"""crypto_index_construction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p78BLOm-XH6EJybK0ROImGfH6ESyxQLf

## Crypto Sentiment Index 2.0

Testing the implementation of the crypto sentiment index construction using Tensorflow 2.0 and the latest crypto messages from StockTwits.
"""

import os

import requests
import tensorflow as tf
from tqdm import tqdm

from data_processor import *
from index_builder import *

"""Set parameters"""

meta_path = '/home/john_oluwagembi/crypto_index_metadata/'
data_path = '/home/john_oluwagembi/stocktwits_data/'
output_path = '/home/john_oluwagembi/crypto_index_output/'

embedding_dim = 100
max_length = 50
test_portion = .1
vocab_size = 10000
num_epochs = 25
weights_path = meta_path + "best_weights.hdf5"
msgs_path = data_path + "all_messages_df_updated.csv"
embeddings_path = meta_path + "glove.6B.100d.txt"
lexicon_path = meta_path + "l2_lexicon.csv"

"""Define helper functions"""


def get_crypto_price(symbol, exchange, start_date, end_date):
    """
    Get crypto prices from Alpha Vantage
    """
    api_key = '04C7KV8HEM4CLQPB'
    api_url = f'https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol={symbol}' \
              f'&market={exchange}&apikey={api_key}'
    raw_df = requests.get(api_url).json()
    df = pd.DataFrame(raw_df['Time Series (Digital Currency Daily)']).T
    df = df.rename(columns={'1a. open (USD)': 'open', '2a. high (USD)': 'high', '3a. low (USD)': 'low',
                            '4a. close (USD)': 'close', '5. volume': 'volume'})
    for i in df.columns:
        df[i] = df[i].astype(float)
    df.index = pd.to_datetime(df.index)
    df = df.iloc[::-1].drop(['1b. open (USD)', '2b. high (USD)', '3b. low (USD)',
                             '4b. close (USD)', '6. market cap (USD)'], axis=1)
    df = df[(df.index >= start_date) & (df.index <= end_date)]
    return df


def main():
    """Read and process data"""
    messages_df = pd.read_csv(msgs_path, index_col=0)
    data_processor = DataProcessor(messages_df, vocabulary_size=vocab_size, min_msg_length=5,
                                   max_msg_length=50, min_term_frequency=20)
    _, _ = data_processor.get_mapped_messages()
    word_index = data_processor.word_to_index_map

    """Get the GloVe embedding matrix"""
    embeddings_index = {}
    with open(embeddings_path) as f:
        for line in f:
            values = line.split()
            word = values[0]
            coefs = np.asarray(values[1:], dtype='float32')
            embeddings_index[word] = coefs

    embeddings_matrix = np.zeros((vocab_size, embedding_dim))
    for word, i in word_index.items():
        embedding_vector = embeddings_index.get(word)
        if embedding_vector is not None:
            embeddings_matrix[i] = embedding_vector

    """Set up and train the model using the optimal learning rate"""
    model = tf.keras.Sequential([
        tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim,
                                  input_length=max_length, weights=[embeddings_matrix], trainable=True),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Conv1D(64, 5, activation='relu'),
        tf.keras.layers.MaxPooling1D(pool_size=4),
        tf.keras.layers.LSTM(64),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])

    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    model.summary()

    """Load the best saved weights into the model"""
    model.load_weights(weights_path)

    """Create the index doing the following:
    *   predict sentiment for unlabeled data
    *   construct sentiment index time series from the classification results
    """

    # ----- get stats on the number of records for each crypto
    seed_df = pd.read_csv(lexicon_path, sep=';')
    messages_df_full = data_processor.messages_df_with_tokens
    print(messages_df_full['symbol'].value_counts().iloc[:10])

    """Get stats on the number of records for each crypto
    1. Get sentiment for BTC
    """
    messages_df_btc = messages_df_full.loc[lambda x: x['symbol'] == 'BTC.X', :]

    # ----- create an index builder object
    index_builder_btc = IndexBuilder(messages_df=messages_df_btc, word2idx=data_processor.word_to_index_map,
                                     w2v_matrix=embeddings_matrix, seed_df=seed_df,
                                     min_msg_length=5, max_msg_length=50, rnn_model=model)
    index_builder_btc.add_classfn_sentiment()
    index_builder_btc.add_w2v_sentiment()
    index_builder_btc.add_classfn_score_1()
    index_builder_btc.add_classfn_score_2()

    # --- plot sentiment for BTC
    indices_scores_df_btc = index_builder_btc.scores_by_day_na
    indices_scores_df_btc.loc[:, ['sentiment_classfn', 'sentiment_w2v']].plot()

    # --- save BTC sentiment to file
    indices_scores_df_btc.to_csv(os.path.join(output_path, 'btc_df.csv'))

    """2. Get sentiment for DOGE"""
    messages_df_doge = messages_df_full.loc[lambda x: x['symbol'] == 'DOGE.X', :]

    # ----- create an index builder object
    index_builder_doge = IndexBuilder(messages_df=messages_df_doge, word2idx=data_processor.word_to_index_map,
                                      w2v_matrix=embeddings_matrix, seed_df=seed_df,
                                      min_msg_length=5, max_msg_length=50, rnn_model=model)
    index_builder_doge.add_classfn_sentiment()
    index_builder_doge.add_w2v_sentiment()
    index_builder_doge.add_classfn_score_1()
    index_builder_doge.add_classfn_score_2()

    # --- plot sentiment for DOGE
    indices_scores_df_doge = index_builder_doge.scores_by_day_na
    indices_scores_df_doge.loc[:, ['sentiment_classfn', 'sentiment_w2v']].plot()

    # --- save DOGE sentiment to file
    indices_scores_df_doge.to_csv(os.path.join(output_path, 'doge_df.csv'))

    """3. Get sentiment for ETH"""
    messages_df_eth = messages_df_full.loc[lambda x: x['symbol'] == 'ETH.X', :]

    # ----- create an index builder object
    index_builder_eth = IndexBuilder(messages_df=messages_df_eth, word2idx=data_processor.word_to_index_map,
                                     w2v_matrix=embeddings_matrix, seed_df=seed_df,
                                     min_msg_length=5, max_msg_length=50, rnn_model=model)
    index_builder_eth.add_classfn_sentiment()
    index_builder_eth.add_w2v_sentiment()
    index_builder_eth.add_classfn_score_1()
    index_builder_eth.add_classfn_score_2()

    # --- plot sentiment for ETH
    indices_scores_df_eth = index_builder_eth.scores_by_day_na
    indices_scores_df_eth.loc[:, ['sentiment_classfn', 'sentiment_w2v']].plot()

    # --- save ETH sentiment to file
    indices_scores_df_eth.to_csv(os.path.join(output_path, 'eth_df.csv'))

    """4. Get sentiment for XRP"""
    messages_df_xrp = messages_df_full.loc[lambda x: x['symbol'] == 'XRP.X', :]

    # ----- create an index builder object
    index_builder_xrp = IndexBuilder(messages_df=messages_df_xrp, word2idx=data_processor.word_to_index_map,
                                     w2v_matrix=embeddings_matrix, seed_df=seed_df,
                                     min_msg_length=5, max_msg_length=50, rnn_model=model)
    index_builder_xrp.add_classfn_sentiment()
    index_builder_xrp.add_w2v_sentiment()
    index_builder_xrp.add_classfn_score_1()
    index_builder_xrp.add_classfn_score_2()

    # --- plot sentiment for XRP
    indices_scores_df_xrp = index_builder_xrp.scores_by_day_na
    indices_scores_df_xrp.loc[:, ['sentiment_classfn', 'sentiment_w2v']].plot()

    # --- save XRP sentiment to file
    indices_scores_df_xrp.to_csv(os.path.join(output_path, 'xrp_df.csv'))

    """Now augment each sentiment file with prices' data
    """
    for filename in tqdm(['btc_df.csv', 'doge_df.csv', 'eth_df.csv', 'xrp_df.csv']):
        ticker = filename.split('_')[0]
        ticker_upper = ticker.upper()
        sentiment_df = pd.read_csv(os.path.join(output_path, filename))
        start_date = sentiment_df['date'].iloc[0]
        end_date = sentiment_df['date'].iloc[-1]
        crypto_data = get_crypto_price(ticker_upper, 'USD', start_date, end_date)
        crypto_data_close = crypto_data.loc[:, ['close']].reset_index() \
            .rename(columns={'index': 'date', 'close': ticker + '_price'})
        crypto_data_close['date'] = crypto_data_close['date'].astype(str)
        sentiment_df = sentiment_df.merge(crypto_data_close, on='date') \
                           .dropna(subset=['classfn_score_1']) \
                           .loc[:, ['date', 'sentiment_classfn',
                                    ticker + '_price']]
        filename_new = filename.split('.')
        filename_new[0] = filename_new[0] + '_with_price'
        filename_new = '.'.join(filename_new)
        sentiment_df.to_csv(os.path.join(output_path, filename_new), index=False)


if __name__ == '__main__':
    main()

